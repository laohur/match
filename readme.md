机器学习项目代码     
1.k邻近
2.NaiveBayes 
3.决策树


算法：
K临近：特征相近聚在一起，常用L2距离。
朴素贝叶斯：鉴定特征都独立影响分类概率，所有特征的影响概率乘积就是标签概率。
决策树：每步根据最大区分度选择特征区分。区分度指标有条件熵、Gini、薪资增益率等。如果是回归任务，则使用大于小于二分类。
Bagging：多次用样本预测，投票出结果。
Boost：多个学习器逐次学习，总损失=各个记录损失*权重。前一个学习器的预测错误记录权重高，后一个学习器就能追踪错误，重点学习错误样本。
GBDT、XGB：总损失函数分别用一阶、二阶的初步损失拟合。
LightGBM：直方图算法，把连续的浮点特征值离散化成k个整数。
